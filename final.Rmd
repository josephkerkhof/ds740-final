---
title: "Predicting On-Time Flight Departures"
author: "Joseph Kerkhof"
date: "4/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The purpose of this model is to try to predict if a flight will be delayed from departure by 15 or more minutes using the [January US Flight data](https://www.kaggle.com/divyansh22/flight-delay-prediction/kernels) dataset. Given that this data is captured in the month of January 2019 and January 2020, it's reasonable to expect that this model may only accurately predict flights in January in the future. In addition, because I want to predict if a flight will be delayed by 15 or more minutes before takeoff, I will not be using data that is captured after the takeoff happens (ex. delayed by 15 or more minutes, diverted, etc.) 

## Cleaning the data

We'll start by cleaning the data and removing variables we won't use in our model building process. By definition of our problem, we aren't able to use variables that are recorded after the flight departs from the origin airport. As an example, we can't use the variable `ARR_DEL15` (a binary variable) which records if a flight arrived at it's destination more than 15 minutes late. In all likelyhood, this variable would be INCREDIBLY powerful in predicting if a flight departed on time (flights that arrive late, tend to depart late as well). Since this happens after the flight departs, we can't use this variable.

```{r}
cleanDataset = function(flight.data){
  # Removing unusable variables
  keeps = c(
    "DAY_OF_WEEK",
    "OP_CARRIER",
    "ORIGIN",
    "DEP_DEL15",
    "DEP_TIME_BLK",
    "DISTANCE"
  )
  flight.data = flight.data[keeps]
  
  # Converting ints to factors
  flight.data$DAY_OF_WEEK = as.factor(flight.data$DAY_OF_WEEK)
  flight.data$DEP_DEL15 = as.factor(flight.data$DEP_DEL15)
  flight.data$DEP_TIME_BLK = as.factor(flight.data$DEP_TIME_BLK)
  flight.data$ORIGIN = as.factor(flight.data$ORIGIN)
  
  # Removing any rows with incomplete data
  flight.data = flight.data[which(complete.cases(flight.data) == TRUE),]

  return(flight.data)
}

jan19 = read.csv('./data/Jan_2019_ontime.csv')
jan20 = read.csv('./data/Jan_2020_ontime.csv')

jan19 = cleanDataset(jan19)
jan20 = cleanDataset(jan20)
flights.full = merge(jan19, jan20)

# making our flight sample smaller so we can build things in a reasonable amount of time
suppressWarnings(set.seed(3, sample.kind = "Rounding")) # setting the seed
flights.20 = flights.full[sample(nrow(flights.full), floor(nrow(flights.full)/20)),] # taking 1/20th of the observations
flights = flights.full[sample(nrow(flights.full), floor(nrow(flights.full)/80)),] # taking 1/40th of the observations

# clearing some space in RAM
rm(jan19)
rm(jan20)
```

## Exploring the data

Looking for collineraity in plotting variables in the dataset against each other.

```{r}
pairs(flights)
```

There's lots of categorical variables, but not too many variables look like they are tending to be collinear.

# Logistic Regression

## Basic Model

We'll start by creating a basic logistic regression.

```{r}
glm.basic.fit = glm(DEP_DEL15 ~ ., data=flights.20, family = "binomial")
```

Now let's see if we get any variance inflation factor (VIF) values that are greater than 10. If so, we should probably consider removing them.

```{r}
suppressWarnings(library(car, quietly = TRUE)) # hide warnings while loading the library
vif(glm.basic.fit)
```

Looking the the generalized variance inflaction factor column, we see variables that have quite a high value, specifically noted in `ORIGIN` and `OP_CARRIER`. In this case thougth, we notice that these are categorical variables and the degrees of freedom are listed in the second column (Df). It is therefore more useful to take a look at the last column which accounts for the degrees of freedom relative to the GVIF. Looking there, we don't have any variables that show a value higher than 10, so we can proceed with keeping all of the variables in the dataset.

## Building/Testing a Model with Cross-Validation

```{r}
n      = nrow(flights)
k      = 10 # using 10-fold cross validation
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))

cvgroups         = sample(groups,n)
predict.glm.vals = rep(-1, n)

for(i in 1:k){
  groupi = (cvgroups == i)
  
  # separating the data
  train = flights[!groupi,]
  test  = flights[groupi,]
  
  cv.glm.fit = glm(DEP_DEL15 ~ ., data=train, family = "binomial")
  
  # updating xlevels in the model object
  # see here: https://stackoverflow.com/questions/22315394/factor-has-new-levels-error-for-variable-im-not-using
  cv.glm.fit$xlevels[["ORIGIN"]] = union(cv.glm.fit$xlevels[["ORIGIN"]], levels(test$ORIGIN))
  
  predict.glm.vals[groupi] = predict(cv.glm.fit, test, type="response")
  print(paste("Finished with fold", i))
}
```

Let's take a look at the ROC curve and find the area under the curve.

```{r}
suppressWarnings(library(pROC, quietly = TRUE))
glm.roc = roc(response=flights$DEP_DEL15, predictor=predict.glm.vals, quiet = TRUE)
plot.roc(glm.roc)
glm.roc
```

This area under the curve is indeed pretty low, but this is probably the case because of the number of categorical variables in the dataset. Let's try to improve the area under the curve by trying a few different models and isolating variables.

## Running Double Cross-Validation

Using double cross validation, we can get a more honest model and try a few different models at the same time.

```{r}
xy.out = flights
n.out = dim(xy.out)[1]

#define the cross-validation splits 
k.out = 10 
groups.out = c(rep(1:k.out,floor(n.out/k.out)),1:(n.out%%k.out))  #produces list of group labels
set.seed(8, sample.kind = "Rounding")
cvgroups.out = sample(groups.out,n.out)  #orders randomly, with seed (8) 

allpredictedCV.out = rep(NA,n.out)

##### model assessment OUTER shell #####
for (j in 1:k.out)  {  #be careful not to re-use loop indices
  groupj.out = (cvgroups.out == j)

  # define the training set for outer loop
  trainxy.out = xy.out[!groupj.out,]
  
  #define the validation set for outer loop
  testxy.out = xy.out[groupj.out,]

  ##############################################
  ###   model selection on trainxy.out       ###
  ##############################################
  ##entire model-fitting process##
  xy.in = trainxy.out  # fixed to be fit ONLY to the training data from the outer split
  n.in = dim(xy.in)[1]
  ncv = 10
  if ((n.in%%ncv) == 0) {
    groups.in= rep(1:ncv,floor(n.in/ncv))} else {
      groups.in=c(rep(1:ncv,floor(n.in/ncv)),(1:(n.in%%ncv)))
    }
  
  cvgroups.in = sample(groups.in,n.in)
  # set up storage
  allpredictedcv10 = matrix(,ncol=4,nrow=n.in)
  
  # with model selection 
  for (i in 1:ncv) {
    newdata.in = xy.in[cvgroups.in==i,]
    
    glm1fit = glm(DEP_DEL15 ~ ., data= xy.in, subset=(cvgroups.in!=i),family=binomial)
    glm1fit$xlevels[["ORIGIN"]] = union(glm1fit$xlevels[["ORIGIN"]], levels(newdata.in$ORIGIN))
    glm1prob = predict(glm1fit,newdata.in,type="response")
    glm1fact = rep(1,dim(newdata.in)[1]); glm1fact[glm1prob > 0.5] = 2
    allpredictedcv10[cvgroups.in==i,1] = glm1fact
    
    glm2fit = glm(DEP_DEL15 ~ .-DISTANCE, data= xy.in, subset=(cvgroups.in!=i),family=binomial)
    glm2fit$xlevels[["ORIGIN"]] = union(glm2fit$xlevels[["ORIGIN"]], levels(newdata.in$ORIGIN))
    glm2prob = predict(glm2fit,newdata.in,type="response")
    glm2fact = rep(1,dim(newdata.in)[1]); glm2fact[glm2prob > 0.5] = 2
    allpredictedcv10[cvgroups.in==i,2] = glm2fact
  }
  #relabel as original values, not factor levels
  allpredictedcv10 = allpredictedcv10-1  # now a table of predicted 0-1 values for HD
  
  #compute the CV values
  allcv10 = rep(0,2)
  for (m in 1:2) allcv10[m] = sum(xy.in$DEP_DEL15!=allpredictedcv10[,m])/n.in
  bestmodels = (1:2)[allcv10 == min(allcv10)]
  ##############################################
  ###   resulting in bestmodels              ###
  ##############################################

  bestmodel = ifelse(length(bestmodels)==1,bestmodels,sample(bestmodels,1))
  print(allcv10)
  print(paste("Best model at outer loop",j,"is",bestmodel))

  if (bestmodel == 1)  {
    glm1fit.train = glm(DEP_DEL15 ~ ., data= trainxy.out, family=binomial)
    glm1fit.train$xlevels[["ORIGIN"]] = union(glm1fit.train$xlevels[["ORIGIN"]], levels(testxy.out$ORIGIN))
    glm1prob.test = predict(glm1fit.train,testxy.out,type="response")
    predictvalid = rep(1,dim(testxy.out)[1]); predictvalid[glm1prob.test > 0.5] = 2
  }
  if (bestmodel == 2)  {
    glm2fit.train = glm(DEP_DEL15 ~ .-DISTANCE, data= trainxy.out, family=binomial)
    glm2fit.train$xlevels[["ORIGIN"]] = union(glm2fit.train$xlevels[["ORIGIN"]], levels(testxy.out$ORIGIN))
    glm2prob.test = predict(glm2fit.train,testxy.out,type="response")
    predictvalid = rep(1,dim(testxy.out)[1]); predictvalid[glm2prob.test > 0.5] = 2
  }
  #relabel as original values, not factor levels
  predictvalid = predictvalid-1  # now a vector of predicted 0-1 values for HD in validation set
  
  allpredictedCV.out[groupj.out] = predictvalid

}

table(flights$DEP_DEL15,allpredictedCV.out)
CV10.out = sum(flights$DEP_DEL15!=allpredictedCV.out)/n.out
p.out = 1-CV10.out; p.out

table(flights$DEP_DEL15)/n.out
```
